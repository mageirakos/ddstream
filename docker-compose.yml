version: '3.7'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper
    container_name: zookeeper
    networks:
      - kafka-spark-net
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:5.5.8 
    container_name: kafka
    depends_on:
      - zookeeper
    networks:
      - kafka-spark-net
    ports:
      - 9092:9092
      - 30001:30001
    environment:
      KAFKA_CREATE_TOPICS: test,test2
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100


  spark-master:
    container_name: spark-master
    build:
      context: .
      dockerfile: DockerfileMasterNumPy
    image: spark-master-numpy
    networks: 
      - kafka-spark-net
    ports:
      - "9080:8080"
      - "9077:7077"
      - "9040:4040"
    volumes:
      - ./shared_data:/data
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    container_name: spark-worker-1
    build:
      context: .
      dockerfile: DockerfileWorkerNumPy
    image: spark-worker-numpy
    networks: 
      - kafka-spark-net
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    volumes:
      - ./shared_data:/data
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-2:
    container_name: spark-worker-2
    build:
      context: .
      dockerfile: DockerfileWorkerNumPy
    image: spark-worker-numpy
    networks: 
      - kafka-spark-net
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    volumes:
      - ./shared_data:/data
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-3:
    container_name: spark-worker-3
    build:
      context: .
      dockerfile: DockerfileWorkerNumPy
    image: spark-worker-numpy
    networks: 
      - kafka-spark-net
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    volumes:
      - ./shared_data:/data
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  # spark-worker-4:
  #   container_name: spark-worker-4
  #   build:
  #     context: .
  #     dockerfile: DockerfileWorkerNumPy
  #   image: spark-worker-numpy
  #   networks: 
  #     - kafka-spark-net
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8084:8081"
  #   volumes:
  #     - ./shared_data:/data
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"

  # spark-worker-5:
  #   container_name: spark-worker-5
  #   build:
  #     context: .
  #     dockerfile: DockerfileWorkerNumPy
  #   image: spark-worker-numpy
  #   networks: 
  #     - kafka-spark-net
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8085:8081"
  #   volumes:
  #     - ./shared_data:/data
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"


  # spark-worker-6:
  #   container_name: spark-worker-6
  #   build:
  #     context: .
  #     dockerfile: DockerfileWorkerNumPy
  #   image: spark-worker-numpy
  #   networks: 
  #     - kafka-spark-net
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8086:8081"
  #   volumes:
  #     - ./shared_data:/data
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"


  # spark-worker-7:
  #   container_name: spark-worker-7
  #   build:
  #     context: .
  #     dockerfile: DockerfileWorkerNumPy
  #   image: spark-worker-numpy
  #   networks: 
  #     - kafka-spark-net
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8087:8081"
  #   volumes:
  #     - ./shared_data:/data
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"

  # spark-worker-8:
  #   container_name: spark-worker-8
  #   build:
  #     context: .
  #     dockerfile: DockerfileWorkerNumPy
  #   image: spark-worker-numpy
  #   networks: 
  #     - kafka-spark-net
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8088:8081"
  #   volumes:
  #     - ./shared_data:/data
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"

networks:
  kafka-spark-net:
    name: kafka-spark-net

volumes:
  shared_data:
    external: true